# -*- coding: utf-8 -*-
"""Trabalho TEAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15dDPKk7iZLqY2r8YugO58U8bh2oYvXnv

# Importando as Bibliotecas
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
pd.set_option("display.max_columns", None)

"""# Análise Exploratória dos Dados"""

dataset = pd.read_csv("insurance.csv")

"""## Exibindo informações relacionadas ao dataset."""

print(dataset.head())

print(dataset.tail())

print(dataset.describe())

print(dataset.shape)

print(dataset.isnull().sum())

"""Podemos verificar através dos dados dispostos acima que o dataset possui 1338 linhas e 7 colunas, sendo as colunas referentes aos dados de idade, IMC, número de filhos, informação se a pessoa é fumante ou não, a região do país (Estados Unidos da América) em que se encontra e por fim o valor cobrado pelo seguro, baseado nos dados anteriormente citados. Podemos notar que o dataset é bem diverso, possuindo dados de pessoas de 18 à 64 anos. O dataset não possui dados em falta, dessa forma podemos prosseguir na análise"""

sns.countplot(x = 'smoker', data = dataset,
              order = dataset['smoker'].value_counts(ascending=False)[0:20].index)
plt.title('Distribuição dos dados entre fumantes e não fumantes')
plt.xlabel('Fumante')
plt.ylabel('Quantidade')
plt.show()

sns.countplot(x = 'sex', data = dataset,
              order = dataset['sex'].value_counts(ascending=False)[0:20].index)
plt.title('Distribuição dos dados entre gêneros')
plt.xlabel('Sexo')
plt.ylabel('Quantidade')
plt.show()

sns.countplot(x = 'region',
              data = dataset,
              order = dataset['region'].value_counts(ascending=False)[0:20].index)
plt.title('Distribuição dos dados entre regiões')
plt.xlabel('Região')
plt.ylabel('Quantidade')
plt.show()

sns.barplot(x='smoker', y='charges', data=dataset)
plt.title('Valores para fumantes e não fumantes')
plt.xlabel('Fumante')
plt.ylabel('Valor')
plt.show()

sns.barplot(x='children', y='charges', data=dataset)
plt.title('Valores de acordo com o número de filhos')
plt.xlabel('Número de filhos')
plt.ylabel('Valor')
plt.show()

sns.barplot(x='region', y='charges', data=dataset)
plt.title('Valores de acordo com a região')
plt.xlabel('Região')
plt.ylabel('Valor')
plt.show()

from sklearn.preprocessing import LabelEncoder
cat_col = ['sex','smoker', 'region']
le = LabelEncoder()
df = dataset
df[cat_col] = df[cat_col].apply(lambda col: le.fit_transform(col.astype(str)))

sns.heatmap(df.corr(),annot=True)
plt.title('Heatmap de correlação')
plt.show()

"""# Regressão Linear"""

from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

s = StandardScaler()
X = dataset.drop(['charges', 'region', 'sex', 'children'], axis=1)
y = dataset.charges

# Add polynomial features
pf = PolynomialFeatures(degree=2, include_bias=False)
X_pf = pd.DataFrame(data=pf.fit_transform(X), columns=pf.get_feature_names(X.columns))

# Create train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_pf, y, test_size=0.2, random_state=0)

# Scale features
X_train_scaled = s.fit_transform(X_train)
X_test_scaled = s.transform(X_test)

# PCA
pca = PCA(.95)
X_train_pca=pca.fit_transform(X_train_scaled)
X_test_pca=pca.transform(X_test_scaled)

# Linear Regression
lr = LinearRegression().fit(X_train_pca, y_train)
y_pred=lr.predict(X_test_pca)
rmse=np.sqrt(mean_squared_error(y_test, y_pred)).round(2)
r2=r2_score(y_test, y_pred)
adj_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test_pca.shape[1]-1)

print(rmse)
print(r2)
print(adj_r2)

"""# Máquinas de Vetores de Suporte"""

from sklearn.model_selection import RandomizedSearchCV
from sklearn.svm import SVR

X = dataset.drop(['charges', 'region', 'sex', 'children'], axis=1)
y = dataset.charges

# Add polynomial features
pf = PolynomialFeatures(degree=2, include_bias=False)
X_pf = pd.DataFrame(data=pf.fit_transform(X), columns=pf.get_feature_names(X.columns))

# Create train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_pf, y, test_size=0.2, random_state=1)
X_train = pd.DataFrame(X_train, columns = X_pf.columns)
X_test = pd.DataFrame(X_test, columns = X_pf.columns)

# Scale features
X_train = pd.DataFrame(data=s.fit_transform(X_train), columns=X_pf.columns)
X_test = pd.DataFrame(data=s.transform(X_test), columns=X_pf.columns)

# Tuning Params
grid = {'kernel':['linear','rbf','poly','sigmoid'],
        'C': np.logspace(-3, 3, 10),
        'gamma':np.logspace(-3, 3, 10)}
svm = SVR()
svm_cv=RandomizedSearchCV(estimator=svm, param_distributions=grid, scoring='neg_mean_squared_error', 
                          n_iter=10, cv=3, random_state=21, n_jobs=-1)
svm_cv.fit(X_train, y_train)
y_pred=svm_cv.predict(X_test)
rmse=np.sqrt(mean_squared_error(y_test, y_pred)).round(2)
r2=r2_score(y_test, y_pred)
adj_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)

print(rmse)
print(r2)
print(adj_r2)

"""# KNN """

from sklearn.neighbors import KNeighborsRegressor

X = dataset.drop(['charges', 'region', 'sex', 'children'], axis=1)
y = dataset.charges

pf = PolynomialFeatures(degree=2, include_bias=False)
X_pf = pd.DataFrame(data=pf.fit_transform(X), columns=pf.get_feature_names(X.columns))

X_train, X_test, y_train, y_test = train_test_split(X_pf, y, test_size=0.2, random_state=1)
X_train = pd.DataFrame(X_train, columns = X_pf.columns)
X_test = pd.DataFrame(X_test, columns = X_pf.columns)

X_train = pd.DataFrame(data=s.fit_transform(X_train), columns=X_pf.columns)
X_test = pd.DataFrame(data=s.transform(X_test), columns=X_pf.columns)

# KNN
grid = {'n_neighbors': range(2, 20),
        'weights': ['uniform', 'distance'],
        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
        'leaf_size': [int(x) for x in np.linspace(10, 50, num = 5)],
        'p': [1, 2]}
knn=KNeighborsRegressor()
knn_cv=RandomizedSearchCV(estimator=knn, param_distributions=grid, scoring='neg_mean_squared_error', 
                          n_iter=100, cv=3, random_state=21, n_jobs=-1)
knn_cv.fit(X_train, y_train)
y_pred=knn_cv.predict(X_test)
rmse=np.sqrt(mean_squared_error(y_test, y_pred)).round(2)
r2=r2_score(y_test, y_pred)
adj_r2 = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)

print(rmse)
print(r2)
print(adj_r2)